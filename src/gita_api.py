"""
Unified Production-Grade API for Talk to Krishna.
Implements multi-stage retrieval RAG system.
"""
# -*- coding: utf-8 -*-
import json
import os
import unicodedata

import re
import pickle
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional, Literal
from fastembed import TextEmbedding
from sklearn.metrics.pairwise import cosine_similarity
from groq import Groq

from src.config import settings
from src.logger import setup_logger
from src.llm_generator import LLMAnswerGenerator
from src.exceptions import InvalidInputError

logger = setup_logger(__name__, settings.LOG_LEVEL, settings.LOG_FILE)

SearchMethod = Literal["hybrid"]  # Only best method remains

class GitaAPI:
    """
    Production-grade RAG system for Bhagavad Gita.
    
    Pipeline:
    1. LLM Query Understanding (extracts topic/concepts)
    2. Hybrid Search (Multilingual Semantic + Keyword)
    3. Cross-Encoder Re-ranking
    4. LLM Answer Generation
    """
    
    def __init__(self, groq_api_key: Optional[str] = None):
        """Initialize system."""
        self.groq_api_key = groq_api_key or settings.GROQ_API_KEY
        
        # Models (Lazy loaded)
        self.semantic_model = None
        self.cross_encoder = None
        self.groq_client = None
        
        # Data
        self.embeddings = None
        self.shlokas = []
        
        # LLM
        self.llm_generator = None
        
        logger.info("GitaAPI initialized (Production Mode)")
    
    def _load_resources(self):
        """Load all data and models if not loaded."""
        if self.shlokas and self.semantic_model:
            return

        logger.info("Loading high-performance models & data...")
        
        # 1. Load Data
        print("Loading Bhagavad Gita verses...")
        
        # Try to load English version first (better for search)
        english_file = Path(settings.gita_emotions_path.parent / "gita_english.json")
        
        if english_file.exists():
            print("   Using English translations for better semantic search")
            with open(english_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                chapters = data.get('chapters', {})
                self.shlokas = []
                for c_num, c_data in chapters.items():
                    for v_num, v_data in c_data.items():
                        # Use English for search, Hindi for display
                        english_meaning = v_data.get('meaning_english', '')
                        hindi_meaning = v_data.get('meaning_hindi', v_data.get('meaning', ''))
                        text = v_data.get('text', '')
                        
                        self.shlokas.append({
                            'id': f"{c_num}.{v_num}",
                            'chapter': int(c_num),
                            'verse': int(v_num),
                            'sanskrit': text,
                            'meaning': hindi_meaning,  # Hindi for display to user
                            'meaning_english': english_meaning,  # English for search
                            # Create rich searchable text with English + Sanskrit
                            'searchable_text': f"{english_meaning} {text}".lower(),
                            'emotions': v_data.get('emotions', {}),
                            'dominant_emotion': v_data.get('dominant_emotion', 'neutral')
                        })
        else:
            # Fallback to Hindi-only version
            print("   English translations not found, using Hindi")
            print("   Run 'python translate_to_english.py' for better search quality")
            
            if not settings.gita_emotions_path.exists():
                raise FileNotFoundError(f"Data missing: {settings.gita_emotions_path}")
                
            with open(settings.gita_emotions_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                chapters = data.get('chapters', {})
                self.shlokas = []
                for c_num, c_data in chapters.items():
                    for v_num, v_data in c_data.items():
                        meaning = v_data.get('meaning', '')
                        text = v_data.get('text', '')
                        self.shlokas.append({
                            'id': f"{c_num}.{v_num}",
                            'chapter': int(c_num),
                            'verse': int(v_num),
                            'sanskrit': text,
                            'meaning': meaning,
                            'meaning_english': meaning,  # Same as Hindi if no English
                            # Create rich searchable text
                            'searchable_text': f"{meaning} {text}".lower(),
                            'emotions': v_data.get('emotions', {}),
                            'dominant_emotion': v_data.get('dominant_emotion', 'neutral')
                        })
        
        print(f"   {len(self.shlokas)} shlokas loaded")
        logger.info(f"Loaded {len(self.shlokas)} shlokas")

        # 2. Load Embeddings
        print("Loading semantic understanding...")
        if not settings.embeddings_path.exists():
             raise FileNotFoundError(f"Embeddings missing. Run rebuild_embeddings.py first!")
             
        with open(settings.embeddings_path, 'rb') as f:
            # Load embeddings
            data = pickle.load(f)
            self.embeddings = data['embeddings']
            
            # Reshape if flattened (FastEmbed/Pickle quirk)
            if self.embeddings.ndim == 1:
                # Deduce dimension from size
                # We know logic: num_verses = 683 (usually)
                # But safer to use the loaded shlokas length
                n_shlokas = len(self.shlokas)
                if n_shlokas > 0:
                    dim = self.embeddings.size // n_shlokas
                    logger.info(f"Reshaping 1D embeddings: {self.embeddings.shape} -> ({n_shlokas}, {dim})")
                    self.embeddings = self.embeddings.reshape(n_shlokas, dim)
                else:
                    # Fallback logic if shlokas not loaded yet (should not happen due to order)
                    pass
            
            # Safety check: Ensure model matches
            saved_model_name = data.get('model_name', '')
            configured_model = settings.SENTENCE_TRANSFORMER_MODEL
            if saved_model_name and saved_model_name != configured_model:
                logger.warning(f"Model mismatch! Saved: {saved_model_name}, Config: {configured_model}")
        
        print("   Embeddings ready")
        logger.info(f"Loaded embeddings: {self.embeddings.shape}")

        # NOTE: Semantic model is loaded LAZILY on first search to save memory
        # This allows the server to start with minimal RAM usage
        logger.info("‚úÖ Data loaded. Semantic model will load on first query.")
        
        # NOTE: Cross-Encoder disabled because we have Hindi data but English Model.
        # The Multilingual Vector Model + Keyword search is much more accurate.
        self.cross_encoder = None 
        
        print("\n‚úÖ Krishna is ready!")
        print("Semantic model will load on first question (saves memory).\n")



        # 4. Initialize Tools
        if self.groq_api_key:
            try:
                self.groq_client = Groq(api_key=self.groq_api_key)
                self.llm_generator = LLMAnswerGenerator(api_key=self.groq_api_key)
            except Exception as e:
                logger.warning(f"Groq init failed: {e}")
    
    def _ensure_semantic_model(self):
        """Lazy load semantic model only when needed."""
        if self.semantic_model is None:
            logger.info(f"üîÑ Loading Semantic Model: {settings.SENTENCE_TRANSFORMER_MODEL}")
            print("Loading AI model (first time only)...")
            self.semantic_model = TextEmbedding(model_name=settings.SENTENCE_TRANSFORMER_MODEL)
            logger.info("‚úÖ Semantic model loaded")
            print("‚úÖ Model ready!\n")

    def _understand_query(self, query: str) -> Dict[str, str]:
        """
        Translate Hindi/Hinglish query to English for semantic search.

        The embedding model (BAAI/bge-small-en-v1.5) is English-only.
        Passing a Hindi query gives garbage similarity scores.
        This method uses a fast Groq call to translate before embedding.

        Returns: { 'original': ..., 'english': ..., 'keywords': ... }
        """
        if not self.groq_client:
            # No Groq client ‚Äî fall back to raw query (degraded quality)
            logger.warning("No Groq client for translation, using raw query")
            return {'original': query, 'english': query, 'keywords': query, 'is_relevant': True}

        try:
            # Smart prompt for Translation + Keyword Extraction + Relevance Check
            prompt = f"""You are the NLU engine for 'Talk to Krishna'.
            
Analyze this query: "{query}"

Determine strictly if this is a SPIRITUAL/LIFE GUIDANCE question or just generic chat/trivia.

Respond in STRICT JSON:
{{
  "rewritten_query": "A clear, specific English statement of the user's core problem for semantic search.",
  "emotional_state": "One of: neutral, confused, angry, fear, distress, crisis, depressive, grateful, happy",
  "keywords": "3-5 key spiritual concepts (e.g., dharma, karma, soul, duty)",
  "is_relevant": true/false
}}

RULES FOR 'is_relevant':
- TRUE if: Personal problem, emotional distress, philosophical question about life/death/God, or requesting spiritual guidance.
- FALSE if: 
  - Cooking/Food recipes (e.g., "chai kaise banaye", "pizza recipe")
  - Math/Science homework (e.g., "2+2", "gravity formula", "calculation", "percentage")
  - Coding/Technical/Software (e.g., "github", "repo", "install", "download", "app", "website", "error fix")
  - General Trivia/GK (e.g., "capital of India", "who won match", "news")
  - Casual chit-chat without depth (e.g., "bored", "tell joke", "hi", "hello")

Examples:
- "Github par repo kaise banaye" -> {{ "rewritten_query": "Github repository creation", "emotional_state": "neutral", "keywords": "tech", "is_relevant": false }}
- "Chai kaise banate hain?" -> {{ "rewritten_query": "How to make tea", "emotional_state": "neutral", "keywords": "cooking", "is_relevant": false }}
- "2+2 kitna hota hai?" -> {{ "rewritten_query": "Math calculation", "emotional_state": "neutral", "keywords": "math", "is_relevant": false }}
- "Aaj weather kaisa hai?" -> {{ "rewritten_query": "Weather forecast", "emotional_state": "neutral", "keywords": "weather", "is_relevant": false }}
- "Python mein list sort kaise kare?" -> {{ "rewritten_query": "Python coding help", "emotional_state": "neutral", "keywords": "coding", "is_relevant": false }}
- "Mummy papa shaadi ke liye nahi maan rahe" -> {{ "rewritten_query": "My parents are not approving my marriage choice, causing family conflict.", "emotional_state": "distress", "keywords": "family duty love conflict", "is_relevant": true }}
- "Man bahut pareshan hai" -> {{ "rewritten_query": "My mind is very restless and I seek peace.", "emotional_state": "confused", "keywords": "mind peace focus", "is_relevant": true }}"""

            resp = self.groq_client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=settings.LLM_CLASSIFIER_MODEL,
                max_tokens=150,
                temperature=0.0,
                stream=False,
                response_format={"type": "json_object"}
            )
            
            raw_content = resp.choices[0].message.content.strip()
            result = json.loads(raw_content)
            
            return {
                'original': query,
                'english': result.get('english', query),
                'rewritten_query': result.get('rewritten_query', result.get('english', query)),
                'emotional_state': result.get('emotional_state', 'neutral'),
                'keywords': result.get('keywords', query),
                'is_relevant': result.get('is_relevant', True)
            }

        except Exception as e:
            logger.error(f"Translation/Analysis failed: {str(e)}")
            # Fallback: Assume relevant
            return {'original': query, 'english': query, 'keywords': query, 'is_relevant': True}

    def _keyword_search(self, query: str, top_k: int = 50) -> List[Tuple[int, float]]:
        """
        Enhanced keyword search with:
        1. Modern Context Mapping (Job, Suicide, Exam -> Specific Shlokas)
        2. Narrative Filtering (Penalize Sanjay/Dhritarashtra verses)
        3. Comprehensive Keyword Matching
        """
        query_lower = query.lower()
        scores = {}
        
        # 1. MODERN CONTEXT MAPPING (The "Bridge")
        # Map modern problems directly to the BEST philosophical shlokas
        modern_mappings = {
            # CRISIS / DESPAIR
            # Best shlokas: 6.5 (uplift yourself), 2.3 (rise from despair),
            #               2.20 (soul is eternal), 18.66 (divine protection)
            # NOTE: The LLM classifier handles all linguistic variants ‚Äî
            #       these are just semantic anchors for the vector search boost.
            'suicide': ['6.5', '2.3', '2.20', '18.66', '9.22'],
            'suicidal': ['6.5', '2.3', '2.20', '18.66', '9.22'],
            'hopeless': ['6.5', '2.3', '18.66', '9.22'],
            'give up': ['6.5', '2.3', '2.14', '18.66'],
            'kill myself': ['6.5', '2.3', '2.20', '18.66'],
            'end my life': ['6.5', '2.3', '2.20', '18.66'],

            # WORK / CAREER / FAILURE
            'job': ['2.47', '2.48', '3.8', '18.47', '18.48'],
            'work': ['2.47', '3.8', '3.19', '18.45', '18.46'],
            'exam': ['2.47', '2.38', '2.14', '6.5'],
            'fail': ['2.47', '2.38', '2.14', '6.5', '2.50'],
            'result': ['2.47', '2.55', '18.11', '5.10'],
            'money': ['2.47', '18.38', '17.20', '16.13'],

            # PARENT / FAMILY CONFLICTS
            'mother': ['3.35', '18.47', '2.47', '2.38', '9.27'],
            'father': ['3.35', '18.47', '2.47', '2.38', '9.27'],
            'mummy': ['3.35', '18.47', '2.47', '2.38', '9.27'],
            'papa': ['3.35', '18.47', '2.47', '2.38', '9.27'],
            'parents': ['3.35', '18.47', '2.47', '2.38', '9.27'],
            'family refuse': ['3.35', '18.47', '2.47'],
            'family against': ['3.35', '18.47', '2.47'],
            'family conflict': ['3.35', '6.9', '2.47'],

            # RELATIONSHIPS / EMOTIONS
            'breakup': ['2.62', '2.63', '2.66', '5.22', '18.54'],
            'love': ['2.62', '2.63', '12.13', '12.14'],
            'lonely': ['6.30', '9.29', '18.54', '13.16'],
            'cheat': ['3.37', '16.21', '16.23'],

            # MENTAL HEALTH
            'depression': ['6.5', '2.3', '6.6', '2.14', '18.66'],
            'anxiety': ['2.14', '6.26', '6.35', '18.66'],
            'stress': ['2.14', '2.56', '2.71', '12.15'],
            'confused': ['2.7', '18.61', '18.66', '18.73'],
            'anger': ['2.63', '16.21', '3.37', '3.38'],
        }

        # Check for modern triggers
        boosted_shlokas = {}  # Changed to dict to store priority
        for term, ids in modern_mappings.items():
            if term in query_lower:
                for priority, sid in enumerate(ids):
                    # Higher boost for earlier positions in the list (bigger gap for priority)
                    boost_value = 15.0 - (priority * 2.5)  # First=15, Second=12.5, Third=10...
                    if sid not in boosted_shlokas or boosted_shlokas[sid] < boost_value:
                        boosted_shlokas[sid] = boost_value
                    
        # 2. DEFINITIVE KEYWORD MAPPING
        keywords = {
            # Core concepts
            'anger': ['krodh', 'gussa', 'krud', 'anger', 'rage', 'wrath', '‡§ï‡•ç‡§∞‡•ã‡§ß', '‡§ó‡•Å‡§∏‡•ç‡§∏‡§æ'],
            'peace': ['shanti', 'calm', 'peace', '‡§∂‡§æ‡§Ç‡§§‡§ø', '‡§∂‡§æ‡§®‡•ç‡§§‡§ø', 'sukh', '‡§∏‡•Å‡§ñ'],
            'fear': ['bhaya', 'dar', 'fear', 'afraid', '‡§≠‡§Ø', '‡§°‡§∞'],
            'action': ['karma', 'action', 'work', '‡§ï‡§∞‡•ç‡§Æ', '‡§ï‡§æ‡§∞‡•ç‡§Ø', '‡§ï‡§∞‡•ç‡§§‡§µ‡•ç‡§Ø'],
            'duty': ['dharma', 'duty', '‡§ß‡§∞‡•ç‡§Æ', '‡§ï‡§∞‡•ç‡§§‡§µ‡•ç‡§Ø', 'kartavya'],
            'knowledge': ['gyan', 'jnana', 'knowledge', '‡§ú‡•ç‡§û‡§æ‡§®', 'vidya', '‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ'],
            'devotion': ['bhakti', 'love', 'devotion', '‡§≠‡§ï‡•ç‡§§‡§ø', '‡§™‡•ç‡§∞‡•á‡§Æ', 'prem'],
            
            # Life & Purpose
            'life': ['jeevan', 'life', '‡§ú‡•Ä‡§µ‡§®', '‡§ú‡•Ä‡§®‡§æ', 'jeena', 'living', '‡§ú‡§ø‡§Ç‡§¶‡§ó‡•Ä', 'zindagi'],
            'path': ['marg', 'path', 'way', '‡§Æ‡§æ‡§∞‡•ç‡§ó', '‡§∞‡§æ‡§π', 'raah', '‡§∞‡§æ‡§∏‡•ç‡§§‡§æ', 'raasta'],
            'purpose': ['uddeshya', 'purpose', 'goal', 'lakshya', '‡§â‡§¶‡•ç‡§¶‡•á‡§∂‡•ç‡§Ø', '‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø', 'aim'],
            'truth': ['satya', 'truth', '‡§∏‡§§‡•ç‡§Ø', 'sach', '‡§∏‡§ö'],
            
            # Mental states
            'mind': ['man', 'manas', 'mind', '‡§Æ‡§®', '‡§Æ‡§®‡§∏', 'buddhi', '‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø'],
            'desire': ['kama', 'iccha', 'desire', '‡§ï‡§æ‡§Æ', '‡§á‡§ö‡•ç‡§õ‡§æ', 'wish', 'vasana', '‡§µ‡§æ‡§∏‡§®‡§æ'],
            'attachment': ['moha', 'asakti', 'attachment', '‡§Æ‡•ã‡§π', '‡§Ü‡§∏‡§ï‡•ç‡§§‡§ø', 'mamta', '‡§Æ‡§Æ‡§§‡§æ'],
            'ego': ['ahamkar', 'ego', '‡§Ö‡§π‡§Ç‡§ï‡§æ‡§∞', 'pride', 'ghamand', '‡§ò‡§Æ‡§Ç‡§°'],
            
            # Spiritual concepts
            'self': ['atma', 'atman', 'self', 'soul', '‡§Ü‡§§‡•ç‡§Æ‡§æ', '‡§∏‡•ç‡§µ'],
            'god': ['ishwar', 'bhagwan', 'god', '‡§à‡§∂‡•ç‡§µ‡§∞', '‡§≠‡§ó‡§µ‡§æ‡§®', '‡§™‡§∞‡§Æ‡§æ‡§§‡•ç‡§Æ‡§æ', 'paramatma'],
            'yoga': ['yoga', '‡§Ø‡•ã‡§ó', 'yog', 'union', 'sadhana', '‡§∏‡§æ‡§ß‡§®‡§æ'],
            'meditation': ['dhyan', 'meditation', '‡§ß‡•ç‡§Ø‡§æ‡§®', '‡§∏‡§Æ‡§æ‡§ß‡§ø', 'samadhi'],
            
            # Emotions & Qualities
            'happiness': ['sukh', 'anand', 'happiness', 'joy', '‡§∏‡•Å‡§ñ', '‡§Ü‡§®‡§Ç‡§¶', '‡§ñ‡•Å‡§∂‡•Ä', 'khushi'],
            'sorrow': ['dukh', 'sorrow', 'pain', '‡§¶‡•Å‡§É‡§ñ', '‡§¶‡•Å‡§ñ', 'grief', 'shok', '‡§∂‡•ã‡§ï'],
            'wisdom': ['vivek', 'pragya', 'wisdom', '‡§µ‡§ø‡§µ‡•á‡§ï', '‡§™‡•ç‡§∞‡§ú‡•ç‡§û‡§æ', 'buddhi', '‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø'],
            'balance': ['samata', 'balance', '‡§∏‡§Æ‡§§‡§æ', '‡§∏‡§Ç‡§§‡•Å‡§≤‡§®', 'santulan', 'equanimity'],
            
            # Actions & Results
            'result': ['phal', 'result', '‡§´‡§≤', 'outcome', 'parinaam', '‡§™‡§∞‡§ø‡§£‡§æ‡§Æ'],
            'renunciation': ['tyag', 'sannyasa', 'renunciation', '‡§§‡•ç‡§Ø‡§æ‡§ó', '‡§∏‡§Ç‡§®‡•ç‡§Ø‡§æ‡§∏'],
            'sacrifice': ['yagya', 'sacrifice', '‡§Ø‡§ú‡•ç‡§û', 'havan', '‡§π‡§µ‡§®'],
            
            # Relationships
            'family': ['parivar', 'family', '‡§™‡§∞‡§ø‡§µ‡§æ‡§∞', 'relatives', '‡§∏‡§Ç‡§¨‡§Ç‡§ß‡•Ä', 'sambandhi'],
            'friend': ['mitra', 'friend', '‡§Æ‡§ø‡§§‡•ç‡§∞', 'dost', '‡§¶‡•ã‡§∏‡•ç‡§§', '‡§∏‡§ñ‡§æ', 'sakha'],
            'enemy': ['shatru', 'enemy', '‡§∂‡§§‡•ç‡§∞‡•Å', 'dushman', '‡§¶‡•Å‡§∂‡•ç‡§Æ‡§®']
        }
        
        scores = {}
        for idx, item in enumerate(self.shlokas):
            txt = item['searchable_text']
            verse_id = item.get('id', '')
            score = 0.0
            
            # 3. DIRECT BOOSTING for modern contexts (priority-based)
            # If shloka ID is in the boosted list for this query, give priority-based boost
            if verse_id in boosted_shlokas:
                score += boosted_shlokas[verse_id]  # Use priority-based boost value
            
            # 4. NARRATIVE FILTER (Penalize non-Krishna speakers for advice queries)
            # If verse is likely narrative (Sanjay/Dhritarashtra speaking), reduce score
            # We want "Sri Bhagavan Uvacha" (God said) or meaningful questions
            sanskrit_start = item.get('sanskrit', '').strip().lower()
            narrator_markers = ['‡§∏‡§û‡•ç‡§ú‡§Ø ‡§â‡§µ‡§æ‡§ö', '‡§Ö‡§∞‡•ç‡§ú‡•Å‡§® ‡§â‡§µ‡§æ‡§ö', '‡§ß‡•É‡§§‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞ ‡§â‡§µ‡§æ‡§ö', 'sanjaya uvacha', 'arjuna uvacha', 'dhritarashtra uvacha']
            
            is_narrative = any(marker in sanskrit_start for marker in narrator_markers)
            if is_narrative:
                # But don't penalize if it's a boosted shloka (sometimes Arjuna's question is relevant context)
                if verse_id not in boosted_shlokas:
                    score -= 5.0  # Penalty for narrative verses

            # Count keyword matches
            matched_categories = 0
            for key, terms in keywords.items():
                query_has_term = any(t in query_lower for t in terms)
                shloka_has_term = any(t in txt for t in terms)
                
                if query_has_term and shloka_has_term:
                    score += 2.5  # Strong boost for keyword match
                    matched_categories += 1
            
            # Bonus for multiple category matches (indicates high relevance)
            if matched_categories >= 2:
                score += matched_categories * 1.0
                        
            if score > 0:
                scores[idx] = score
                
        # Sort by score
        sorted_indices = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return sorted_indices[:top_k]

    def _semantic_search(self, query: str, top_k: int = 50) -> List[Tuple[int, float]]:
        """Deep semantic vector search."""
        if self.embeddings is None:
            return []
        
        # Lazy load model on first use
        self._ensure_semantic_model()
        
        if not self.semantic_model:
            return []
             
        try:
            # FastEmbed returns a generator of numpy arrays (batches)
            # For a single query, we get one generator that yields batches
            embedding_gen = self.semantic_model.embed([query])
            
            # Consume generator to get the first batch
            # embed() yields np.ndarray of shape (batch_size, dim)
            # Since input is length 1, result is likely one batch of shape (1, dim)
            first_batch = next(embedding_gen)
            
            if first_batch is None or first_batch.size == 0:
                 logger.error("FastEmbed returned empty embedding")
                 return []
                 
            # Ensure 2D (1, dim)
            if first_batch.ndim == 1:
                q_vec = first_batch.reshape(1, -1)
            else:
                q_vec = first_batch
            
            
            # Should be (1, 384) for single query
            if q_vec.shape[0] != 1:
                logger.warning(f"Expected 1 query embedding, got {q_vec.shape[0]}. Using first.")
                q_vec = q_vec[0:1]
            
            # Verify shapes
            if q_vec.shape[1] != self.embeddings.shape[1]:
                logger.error(f"Dimension mismatch: query {q_vec.shape[1]} vs embeddings {self.embeddings.shape[1]}")
                return []

            if len(self.embeddings) == 0:
                 return []

            # Compute similarities
            sims = cosine_similarity(q_vec, self.embeddings)[0]
            
        except Exception as e:
            logger.error(f"Semantic search failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []
            
        # Get indices
        idxs = np.argsort(sims)[::-1][:top_k]
        return [(int(i), float(sims[i])) for i in idxs]

    def _rerank_with_llm(self, query: str, rewritten: str, candidates: List[Dict]) -> List[Dict]:
        """
        Use LLM to rerank top candidates based on relevance to the specific problem.
        This provides a 'second opinion' to fix vector search blind spots.
        """
        if not self.groq_client or not candidates:
            return candidates

        try:
            # Format candidates for LLM review
            options_text = ""
            for i, c in enumerate(candidates, 1):
                options_text += f"Option {i} (ID {c['id']}): {c['meaning_english'][:300]}\n"
            
            prompt = f"""You are a spiritual expert. Rerank these Bhagavad Gita verses based on their relevance to this user's problem.
            
User: "{rewritten}" (Original: "{query}")

Verses:
{options_text}

Task:
1. Identify the MOST relevant verse that directly provides a solution or perspective.
2. Order them from Best to Worst.
3. Return ONLY a list of IDs in JSON format.

Example: ["2.47", "18.66"]"""
            
            resp = self.groq_client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=settings.LLM_CLASSIFIER_MODEL,
                max_tokens=200,
                temperature=0.0,
                response_format={"type": "json_object"}
            )
            
            content = resp.choices[0].message.content.strip()
            # Handle potential wrapper keys
            try:
                data = json.loads(content)
                if isinstance(data, list):
                    ranked_ids = data
                elif isinstance(data, dict):
                     # extensive search for list in values
                     ranked_ids = next((v for v in data.values() if isinstance(v, list)), [])
                else:
                    ranked_ids = []
            except:
                ranked_ids = []
            
            # Create a map for O(1) lookup
            candidate_map = {c['id']: c for c in candidates}
            
            # Reconstruct list in new order
            reranked = []
            seen = set()
            for rid in ranked_ids:
                if rid in candidate_map and rid not in seen:
                    reranked.append(candidate_map[rid])
                    seen.add(rid)
            
            # Append any missing ones at the end
            for c in candidates:
                if c['id'] not in seen:
                    reranked.append(c)
                    
            if reranked:
                logger.info(f"LLM Reranked top result: {reranked[0]['id']}")
            return reranked
            
        except Exception as e:
            logger.warning(f"Reranking failed: {e}")
            return candidates

    def search(self, query: str, method: str = "hybrid", top_k: int = 10, understanding: Dict = None, **kwargs) -> List[Dict[str, Any]]:
        """
        Multi-Perspective Search Strategy to find the 'Sahi Shloka'.
        """
        self._load_resources()
        
        # 1. Understanding
        variations = understanding if understanding else self._understand_query(query)
        rewritten_query = variations.get('rewritten_query', query)
        emotional_state = variations.get('emotional_state', 'neutral')
        
        candidates = {} # Map id -> score
        
        # 2. Search from English Perspective (Semantic Vectors work best here)
        # Use rewritten query for better semantic match
        eng_res = self._semantic_search(rewritten_query, top_k=75)
        for idx, score in eng_res:
            candidates[idx] = candidates.get(idx, 0.0) + score
            
        # 3. Search from Keyword Perspective (Catch specific Sanskrit terms)
        kw_query = f"{variations.get('keywords', '')} {query}"
        kw_res = self._keyword_search(kw_query, top_k=50) 
        for idx, score in kw_res:
            candidates[idx] = candidates.get(idx, 0.0) + (score * 1.5)
            
        # 4. Search Original (Context)
        orig_res = self._semantic_search(query, top_k=75)
        for idx, score in orig_res:
            candidates[idx] = candidates.get(idx, 0.0) + score

        # 5. Apply Emotion Filters & Verification
        # Map LLM emotional state to JSON keys
        emotion_map = {
            'angry': 'anger',
            'confused': 'confusion',
            'happy': 'happiness',
            'grateful': 'devotion',
            'depressive': 'sadness',
            'distress': 'sadness',
            'peace': 'peace',
            'fear': 'fear',
            'duty': 'duty'
        }
        target_emotion = emotion_map.get(emotional_state, emotional_state)
        
        for idx in list(candidates.keys()):
            shloka = self.shlokas[idx]
            
            # Boost if shloka's dominant emotion matches user's state
            if target_emotion != 'neutral' and target_emotion in shloka.get('emotions', {}):
                 # Check strength
                 strength = shloka.get('emotions', {}).get(target_emotion, 0)
                 if strength > 0.4:
                     # Calculate boost based on strength
                     boost = 3.0 * (strength + 0.5) # Dynamic boost
                     candidates[idx] += boost 
            
            # Penalize generic/narrative verses unless boosted by keywords
            verse_id = shloka.get('id', '')
            # (Narrative penalty logic is already in keyword search, but let's reinforce if needed)

        initial_results = []
        # Create a list of dictionaries with scores for debugging
        debug_candidates = []
        
        # Sort by score for initial selection
        sorted_candidates = sorted(candidates.items(), key=lambda item: item[1], reverse=True)
        top_pool_idxs = [idx for idx, score in sorted_candidates[:15]]
        
        for idx in top_pool_idxs:
            shloka_copy = self.shlokas[idx].copy()
            shloka_copy['score'] = candidates[idx]
            initial_results.append(shloka_copy)
            
        # 6. LLM Reranking (The Final Judge)
        # Rerank the top 15 to find the true best 5
        final_results = self._rerank_with_llm(query, rewritten_query, initial_results)
            
        logger.info(f"Returning {min(len(final_results), top_k)} matches after refinement.")
        
        # Return debug info if requested
        if kwargs.get('debug', False):
            debug_info = {
                'rewritten_query': rewritten_query,
                'emotional_state': emotional_state,
                'keywords': variations.get('keywords', ''),
                'initial_pool': [f"{r['id']} (Score: {r.get('score', 0):.2f})" for r in initial_results],
                'final_ranked': [r['id'] for r in final_results[:top_k]]
            }
            return final_results[:top_k], debug_info
            
        return final_results[:top_k]

    def _is_greeting(self, query: str) -> bool:
        """Check if the query is a simple greeting."""
        # Comprehensive list of greetings in multiple languages
        greetings = {
            # English greetings
            "hi", "hello", "hey", "hii", "hiii", "helo", "heyy", "heya", "yo",
            "greetings", "good morning", "good afternoon", "good evening", "good night",
            "gm", "ge", "gn", "ga", "morning", "evening", "afternoon",
            
            # Hindi/Sanskrit greetings (Romanized)
            "namaste", "namaskar", "namaskaram", "pranam", "pranaam", "pranaams",
            "radhe radhe", "radhey radhey", "radhe", "radhey",
            "jai shri krishna", "jai shree krishna", "jai sri krishna", 
            "hare krishna", "hare krsna", "krishna", "krsna",
            "jai", "jay", "om", "aum",
            
            # Hindi Devanagari Script Greetings
            "‡§π‡•á‡§≤‡•ã", "‡§π‡•á‡§≤‡•ç‡§≤‡•ã", "‡§π‡§æ‡§Ø", "‡§π‡§æ‡§à", "‡§π‡§≤‡•ã",
            "‡§®‡§Æ‡§∏‡•ç‡§§‡•á", "‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞", "‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞‡§Æ", "‡§™‡•ç‡§∞‡§£‡§æ‡§Æ", "‡§™‡•ç‡§∞‡§®‡§æ‡§Æ",
            "‡§∞‡§æ‡§ß‡•á ‡§∞‡§æ‡§ß‡•á", "‡§∞‡§æ‡§ß‡•á", "‡§∞‡§æ‡§ß‡•á‡§Ø ‡§∞‡§æ‡§ß‡•á‡§Ø",
            "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä ‡§ï‡•É‡§∑‡•ç‡§£", "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä‡§ï‡•É‡§∑‡•ç‡§£", "‡§ú‡§Ø ‡§ï‡•É‡§∑‡•ç‡§£",
            "‡§π‡§∞‡•á ‡§ï‡•É‡§∑‡•ç‡§£", "‡§π‡§∞‡•á ‡§ï‡•É‡§∑‡•ç‡§£‡§æ", "‡§ï‡•É‡§∑‡•ç‡§£",
            "‡§ú‡§Ø", "‡§ì‡§Æ", "‡•ê",
            "‡§∏‡•Å‡§™‡•ç‡§∞‡§≠‡§æ‡§§", "‡§∂‡•Å‡§≠ ‡§∏‡§Ç‡§ß‡•ç‡§Ø‡§æ", "‡§∂‡•Å‡§≠ ‡§∞‡§æ‡§§‡•ç‡§∞‡§ø",
            "‡§ï‡•à‡§∏‡•á ‡§π‡•ã", "‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç", "‡§ï‡•ç‡§Ø‡§æ ‡§π‡§æ‡§≤", "‡§ï‡•ç‡§Ø‡§æ ‡§π‡§æ‡§≤ ‡§π‡•à",
            
            # Casual/Informal
            "sup", "wassup", "whatsup", "howdy", "hola",
            "kaise ho", "kaise hain", "kya haal", "kya hal", "namaskaar"
        }
        
        # Normalize: remove only punctuation, preserve all letters (including Devanagari)
        # Keep alphanumeric + spaces + Devanagari combining marks
        import unicodedata
        cleaned = ''.join(c for c in query.lower() if c.isalnum() or c.isspace() or unicodedata.category(c).startswith('M'))
        words = cleaned.split()
        
        if not words:
            return False
        
        # Check if entire query is a greeting phrase (like "good morning")
        full_query = ' '.join(words)
        if full_query in greetings:
            return True
        
        # Check for two-word greeting phrases
        if len(words) >= 2:
            two_word = f"{words[0]} {words[1]}"
            if two_word in greetings:
                # If it's just the greeting or greeting + name, it's a greeting
                if len(words) <= 3:
                    return True
                # If longer, check for question words
                question_words = {'what', 'how', 'why', 'who', 'when', 'where', 
                                'kya', 'kyun', 'kaise', 'kab', 'kahan', 'kaun',
                                'explain', 'tell', 'batao', 'bataiye', 'btao'}
                if not any(qw in words for qw in question_words):
                    return True
        
        # STRICT CHECK: Very short queries (1-3 words) - just needs ONE greeting word
        if len(words) <= 3:
            return any(w in greetings for w in words)
        
        # MODERATE CHECK: Slightly longer (4-6 words) - must START with greeting
        # and NOT contain question words
        if len(words) <= 6:
            if words[0] in greetings:
                question_words = {'what', 'how', 'why', 'who', 'when', 'where', 
                                'kya', 'kyun', 'kaise', 'kab', 'kahan', 'kaun',
                                'explain', 'tell', 'batao', 'bataiye', 'btao',
                                'is', 'are', 'can', 'should', 'would', 'could'}
                # If no question words found, it's likely just a greeting
                if not any(qw in words for qw in question_words):
                    return True
        
        return False

    def _is_relevant_to_krishna(self, query: str) -> Tuple[bool, str]:
        """
        Check if the query is relevant to Krishna, Bhagavad Gita, or spiritual life guidance.
        Returns: (is_relevant: bool, rejection_message: str if not relevant)
        
        This prevents the model from answering out-of-context questions like:
        - Sports (cricket, football, etc.)
        - Politics (current affairs, politicians)
        - General trivia (celebrities, movies, etc.)
        - Science facts unrelated to spirituality
        """
        query_lower = query.lower()
        
        # IRRELEVANT TOPICS - These should be rejected
        irrelevant_patterns = {
            # Sports & Games (Cricket, Football, General)
            'sports': ['cricket', 'football', 'soccer', 'match', 'ipl', 'world cup', 'player', 
                      'team', 'score', 'goal', 'wicket', 'stadium', 'olympics', 'tennis',
                      'ind vs', 'india vs', 'pakistan vs', 'match update', 'live score',
                      'ball', 'bat', 'over', 'six', 'four', 'boundary', 'lbw', 'out', 'catch',
                      'drs', 'review', 'umpire', 'captain', 'coach', 'tournament', 'series',
                      'fifa', 'messi', 'ronaldo', 'virat', 'kohli', 'dhoni', 'rohit', 'game',
                      'badminton', 'hockey', 'chess', 'bgmi', 'pubg', 'video game', 'kabaddi',
                      '‡§ï‡•ç‡§∞‡§ø‡§ï‡•á‡§ü', '‡§Æ‡•à‡§ö', '‡§∏‡•ç‡§ï‡•ã‡§∞', '‡§Ü‡§à‡§™‡•Ä‡§è‡§≤', '‡§ñ‡§ø‡§≤‡§æ‡§°‡§º‡•Ä', '‡§ü‡•Ä‡§Æ', '‡§µ‡§ø‡§ï‡•á‡§ü', '‡§õ‡§ï‡•ç‡§ï‡§æ', '‡§ö‡•å‡§ï‡§æ',
                      '‡§°‡•Ä‡§Ü‡§∞‡§è‡§∏', '‡§Ö‡§Ç‡§™‡§æ‡§Ø‡§∞', '‡§´‡•Å‡§ü‡§¨‡•â‡§≤', '‡§Æ‡•á‡§°‡§≤', '‡§ì‡§≤‡§Ç‡§™‡§ø‡§ï', '‡§¨‡•à‡§°‡§Æ‡§ø‡§Ç‡§ü‡§®', '‡§ß‡•ã‡§®‡•Ä', '‡§ï‡•ã‡§π‡§≤‡•Ä'],
            
            # Politics & Current Affairs
            'politics': ['election', 'minister', 'president', 'prime minister', 'parliament',
                        'government', 'party', 'vote', 'donald trump', 'biden', 'modi',
                        'congress', 'bjp', 'political', 'democracy', 'neta', 'chunav', 'voting',
                        'pm', 'cm', 'mla', 'mp', 'sansad', 'vidhan sabha', 'lok sabha', 'news',
                        '‡§ö‡•Å‡§®‡§æ‡§µ', '‡§®‡•á‡§§‡§æ', '‡§Æ‡•ã‡§¶‡•Ä', '‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä', '‡§∏‡§∞‡§ï‡§æ‡§∞', '‡§µ‡•ã‡§ü', '‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä', '‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏',
                        '‡§∞‡§æ‡§ú‡§®‡•Ä‡§§‡§ø', '‡§∏‡§Æ‡§æ‡§ö‡§æ‡§∞', '‡§ñ‡§¨‡§∞', '‡§®‡•ç‡§Ø‡•Ç‡§ú‡§º'],
            
            # Entertainment & Celebrity
            'entertainment': ['movie', 'film', 'actor', 'actress', 'bollywood', 'hollywood',
                            'tv show', 'series', 'netflix', 'celebrity', 'singer', 'song',
                            'hero', 'heroine', 'star', 'release date', 'box office', 'hit', 'flop',
                            'salman', 'shahrukh', 'amitabh', 'reels', 'instagram', 'tiktok',
                            'youtube channel', 'subscriber', 'views', 'viral',
                            '‡§´‡§ø‡§≤‡•ç‡§Æ', '‡§Æ‡•Ç‡§µ‡•Ä', '‡§π‡•Ä‡§∞‡•ã', '‡§π‡•Ä‡§∞‡•ã‡§á‡§®', '‡§∏‡§≤‡§Æ‡§æ‡§®', '‡§∂‡§æ‡§π‡§∞‡•Å‡§ñ', '‡§ó‡•Ä‡§§', '‡§ó‡§æ‡§®‡§æ',
                            '‡§∏‡•Ä‡§∞‡§ø‡§Ø‡§≤', '‡§®‡•á‡§ü‡§´‡•ç‡§≤‡§ø‡§ï‡•ç‡§∏', '‡§µ‡§æ‡§Ø‡§∞‡§≤', '‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã'],
            
            # Technology & Products (only product/tech questions, NOT social media life problems)
            'technology': ['iphone', 'android', 'laptop', 'computer', 'software', 'app', 'website',
                         'microsoft', 'apple inc', 'samsung', 'coding', 'programming', 
                         'python code', 'java code', 'excel formula', 'python mein', 
                         'code likho', 'sort list', 'loop in', 'function in',
                         'github', 'repo', 'git', 'install', 'download', 'upload', 'server', 'database',
                         'error', 'bug', 'fix', 'wifi', 'internet', 'mobile', 'phone', 'battery',
                         'charger', 'sim', 'network', '4g', '5g', 'bluetooth', 'mouse', 'keyboard',
                         'hack', 'password', 'login', 'signup', 'account', 'delete',
                         '‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§∞', '‡§≤‡•à‡§™‡§ü‡•â‡§™', '‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤', '‡§´‡§º‡•ã‡§®', '‡§ö‡§æ‡§∞‡•ç‡§ú‡§∞', '‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü', '‡§µ‡§æ‡§à‡§´‡§æ‡§à',
                         '‡§ê‡§™', '‡§∏‡•â‡§´‡•ç‡§ü‡§µ‡•á‡§Ø‡§∞', '‡§á‡§Ç‡§∏‡•ç‡§ü‡•â‡§≤', '‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§°', '‡§π‡•à‡§ï‡§ø‡§Ç‡§ó', '‡§™‡§æ‡§∏‡§µ‡§∞‡•ç‡§°', '‡§Ö‡§ï‡§æ‡§â‡§Ç‡§ü',
                         '‡§™‡§æ‡§Ø‡§•‡§®', '‡§ú‡§æ‡§µ‡§æ', '‡§ï‡•ã‡§°‡§ø‡§Ç‡§ó', '‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ‡§ø‡§Ç‡§ó', '‡§ó‡§ø‡§†‡•Ç‡§¨', '‡§∞‡•á‡§™‡•ã',
                         'javascript', 'js', 'html', 'css', 'react', 'node', 'frontend', 'backend'],
            
            # Finance & Money (Investment, Banking)
            'finance': ['stock market', 'share market', 'invest', 'investment', 'mutual fund',
                       'crypto', 'bitcoin', 'ethereum', 'trading', 'profit', 'loss', 'bank',
                       'account open', 'loan', 'credit card', 'debit card', 'interest rate',
                       'tax', 'gst', 'salary', 'income', 'earning', 'money making', 'rich fast',
                       'lottery', 'gambling', 'betting', 'paisa kaise', 'kamao', 'kamana',
                       'gold', 'silver', 'price', 'rate', 'rupee', 'dollar', 'euro', 'double money', 'scheme',
                       '‡§∂‡•á‡§Ø‡§∞ ‡§¨‡§æ‡§ú‡§æ‡§∞', '‡§®‡§ø‡§µ‡•á‡§∂', '‡§¨‡•à‡§Ç‡§ï', '‡§≤‡•ã‡§®', '‡§ï‡•ç‡§∞‡•á‡§°‡§ø‡§ü ‡§ï‡§æ‡§∞‡•ç‡§°', '‡§∏‡•à‡§≤‡§∞‡•Ä', '‡§ï‡§Æ‡§æ‡§à',
                       '‡§™‡•à‡§∏‡§æ ‡§ï‡•à‡§∏‡•á', '‡§≤‡•â‡§ü‡§∞‡•Ä', '‡§∏‡§ü‡•ç‡§ü‡§æ', '‡§¨‡§ø‡§ü‡§ï‡•â‡§á‡§®', '‡§∏‡•ã‡§®‡§æ', '‡§ö‡§æ‡§Ç‡§¶‡•Ä', '‡§≠‡§æ‡§µ', '‡§ï‡•Ä‡§Æ‡§§'],

            # General Trivia / Math / School / GK
            'trivia': ['capital of', 'largest', 'smallest', 'tallest', 'fastest',
                      'population', 'currency', 'flag', 'who invented', 'when was',
                      'historical event', 'world war', 'discovery', '2+2', 'calculate', 
                      'solve x', 'math problem', 'kitna hota hai', 'plus', 'minus', 
                      'multiply', 'divide', 'equation', 'formula', 'theorem', 'geometry',
                      'algebra', 'trigonometry', 'physics', 'chemistry', 'biology', 'history',
                      'geography quiz', 'general knowledge', 'gk question', 'who is', 'kon hai',
                      'titanic', 'padosi', 'neighbor', 'joke', 'kahani', 'story', 'chutkula', 'lol', 'rofl',
                      'tie a tie', 'height of', 'distance between', 'mount everest',
                      '‡§∞‡§æ‡§ú‡§ß‡§æ‡§®‡•Ä', '‡§∏‡§¨‡§∏‡•á ‡§¨‡§°‡§º‡§æ', '‡§á‡§§‡§ø‡§π‡§æ‡§∏', '‡§ó‡§£‡§ø‡§§', '‡§ú‡•ã‡§°‡§º', '‡§ò‡§ü‡§æ‡§®‡§æ', '‡§ó‡•Å‡§£‡§æ', '‡§≠‡§æ‡§ó',
                      '‡§ú‡•ç‡§Ø‡§æ‡§Æ‡§ø‡§§‡§ø', '‡§´‡•â‡§∞‡•ç‡§Æ‡•Ç‡§≤‡§æ', '‡§∏‡•Ç‡§§‡•ç‡§∞', '‡§™‡§π‡•á‡§≤‡•Ä', '‡§ö‡•Å‡§ü‡§ï‡•Å‡§≤‡§æ', '‡§ï‡§π‡§æ‡§®‡•Ä', '‡§™‡§°‡§º‡•ã‡§∏‡•Ä', '‡§ï‡•å‡§® ‡§π‡•à'],
            
            # Science (unless spiritual)
            'science': ['chemical formula', 'periodic table', 'molecule', 'bacteria',
                       'virus covid', 'vaccine', 'dna', 'atom', 'neutron', 'electron', 'gravity', 'physics',
                       'solar system', 'planet', 'mars', 'moon distance', 'sun distance', 'earth',
                       'evolution', 'big bang', 'black hole', 'nasa', 'isro', 'space', 'rocket',
                       'photosynthesis', 'plant', 'animal',
                       '‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§®', '‡§ó‡•ç‡§∞‡§π', '‡§™‡•É‡§•‡•ç‡§µ‡•Ä', '‡§∏‡•Ç‡§∞‡•ç‡§Ø', '‡§ö‡§æ‡§Ç‡§¶', '‡§Æ‡§Ç‡§ó‡§≤', '‡§Ö‡§Ç‡§§‡§∞‡§ø‡§ï‡•ç‡§∑', '‡§∞‡•â‡§ï‡•á‡§ü',
                       '‡§™‡§∞‡§Æ‡§æ‡§£‡•Å', '‡§Ö‡§£‡•Å', '‡§µ‡§æ‡§Ø‡§∞‡§∏', '‡§µ‡•à‡§ï‡•ç‡§∏‡•Ä‡§®', '‡§°‡•Ä‡§è‡§®‡§è', '‡§ó‡•ç‡§∞‡•á‡§µ‡§ø‡§ü‡•Ä'],
            
            # Food & Cooking (STRICT REJECTION)
            'food': ['recipe', 'how to cook', 'ingredients', 'restaurant',
                    'pizza', 'burger', 'pasta', 'italian food', 'chai kaise', 'coffee kaise',
                    'khana kaise', 'make tea', 'make coffee', 'biryani', 'maggie', 'paneer',
                    'chicken', 'mutton', 'fish', 'egg', 'veg', 'non-veg', 'dish', 'swiggy', 'zomato',
                    'samosa', 'cake', 'bread', 'roti', 'dal', 'sabji', 'breakfast', 'lunch', 'dinner',
                    '‡§∞‡•á‡§∏‡§ø‡§™‡•Ä', '‡§¨‡§®‡§æ‡§è', '‡§ñ‡§æ‡§®‡§æ', '‡§∞‡§∏‡•ã‡§à', '‡§ö‡§æ‡§Ø', '‡§ï‡•â‡§´‡•Ä', '‡§™‡§ø‡§ú‡§º‡•ç‡§ú‡§º‡§æ', '‡§¨‡§∞‡•ç‡§ó‡§∞', '‡§™‡§æ‡§∏‡•ç‡§§‡§æ',
                    '‡§¨‡§ø‡§∞‡§Ø‡§æ‡§®‡•Ä', '‡§™‡§®‡•Ä‡§∞', '‡§ö‡§ø‡§ï‡§®', '‡§Æ‡§ü‡§®', '‡§Ö‡§Ç‡§°‡§æ', '‡§∏‡§Æ‡•ã‡§∏‡§æ', '‡§ï‡•á‡§ï', '‡§∞‡•ã‡§ü‡•Ä', '‡§∏‡§¨‡•ç‡§ú‡•Ä'],
            
            # Weather & Geography (factual)
            'geography': ['weather', 'temperature', 'forecast', 'rain tomorrow',
                         'climate in', 'map of', 'distance between', 'mausam', 'barish', 'dhup',
                         'garmi', 'sardi', 'thand', 'monsoon', 'humidity', 'degree celsius',
                         'bus', 'train', 'flight', 'ticket', 'booking',
                         '‡§Æ‡•å‡§∏‡§Æ', '‡§¨‡§æ‡§∞‡§ø‡§∂', '‡§ß‡•Ç‡§™', '‡§ó‡§∞‡•ç‡§Æ‡•Ä', '‡§∏‡§∞‡•ç‡§¶‡•Ä', '‡§†‡§Ç‡§°', '‡§§‡§æ‡§™‡§Æ‡§æ‡§®', '‡§°‡§ø‡§ó‡•ç‡§∞‡•Ä',
                         '‡§Æ‡•å‡§∏‡§Æ', '‡§¨‡§æ‡§∞‡§ø‡§∂', '‡§ß‡•Ç‡§™', '‡§ó‡§∞‡•ç‡§Æ‡•Ä', '‡§∏‡§∞‡•ç‡§¶‡•Ä', '‡§†‡§Ç‡§°', '‡§§‡§æ‡§™‡§Æ‡§æ‡§®', '‡§°‡§ø‡§ó‡•ç‡§∞‡•Ä',
                         '‡§¨‡§∏', '‡§ü‡•ç‡§∞‡•á‡§®', '‡§´‡•ç‡§≤‡§æ‡§á‡§ü', '‡§π‡§µ‡§æ‡§à ‡§ú‡§π‡§æ‡§ú', '‡§ü‡§ø‡§ï‡§ü', '‡§¨‡•Å‡§ï‡§ø‡§Ç‡§ó',
                         # Unicode Matches (Guaranteed)
                         '\u0915\u094d\u0930\u093f\u0915\u0947\u091f', # cricket
                         '\u0921\u0940\u0906\u0930\u090f\u0938', # drs
                         '\u0938\u092e\u094b\u0938\u093e', # samosa
                         '\u092c\u0938']
        }
        
        # Check for irrelevant patterns
        norm_query = unicodedata.normalize('NFKC', query).casefold()
        
        for category, patterns in irrelevant_patterns.items():
            for pattern in patterns:
                nm_pat = unicodedata.normalize('NFKC', pattern).casefold()
                # Use word boundaries to avoid substring matches (e.g., 'match' in 'attachment')
                # For Devanagari, we use a simple boundary check
                if re.search(rf'\b{re.escape(nm_pat)}\b', norm_query) or nm_pat in norm_query.split():
                    logger.warning(f"‚ùå Irrelevant query detected ({category}): '{query}'")
                    return False, f"""‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•à‡§Ç ‡§∂‡•ç‡§∞‡•Ä ‡§ï‡•É‡§∑‡•ç‡§£ ‡§π‡•Ç‡§Å ‡§î‡§∞ ‡§ï‡•á‡§µ‡§≤ ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç, ‡§Ü‡§ß‡•ç‡§Ø‡§æ‡§§‡•ç‡§Æ‡§ø‡§ï‡§§‡§æ, ‡§î‡§∞ ‡§≠‡§ó‡§µ‡§¶ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•á ‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§® ‡§¶‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å‡•§

‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç:
‚Ä¢ ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® (‡§ï‡•ç‡§∞‡•ã‡§ß, ‡§°‡§∞, ‡§ö‡§ø‡§Ç‡§§‡§æ, etc.)
‚Ä¢ ‡§ï‡§∞‡•ç‡§Æ, ‡§ß‡§∞‡•ç‡§Æ, ‡§î‡§∞ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç
‚Ä¢ ‡§∞‡§ø‡§∂‡•ç‡§§‡•ã‡§Ç ‡§î‡§∞ ‡§≠‡§æ‡§µ‡§®‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç
‚Ä¢ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§∂‡§æ‡§Ç‡§§‡§ø, ‡§î‡§∞ ‡§Ü‡§§‡•ç‡§Æ-‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç

‡§ï‡•É‡§™‡§Ø‡§æ ‡§á‡§® ‡§µ‡§ø‡§∑‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡•á‡§Ç‡•§ üôè"""
        
        # RELEVANT KEYWORDS - These indicate the query is likely relevant
        relevant_keywords = [
            # Krishna & Deities
            'krishna', '‡§ï‡•É‡§∑‡•ç‡§£', '‡§≠‡§ó‡§µ‡§æ‡§®', 'bhagwan', 'god', 'ishwar', '‡§à‡§∂‡•ç‡§µ‡§∞',
            'arjun', '‡§Ö‡§∞‡•ç‡§ú‡•Å‡§®', 'radha', '‡§∞‡§æ‡§ß‡§æ', 'vishnu', '‡§µ‡§ø‡§∑‡•ç‡§£‡•Å',

            # Bhagavad Gita & Scriptures
            'gita', '‡§ó‡•Ä‡§§‡§æ', 'shloka', '‡§∂‡•ç‡§≤‡•ã‡§ï', 'verse', 'chapter', '‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§Ø',
            'scripture', 'sacred', 'holy', 'divine',

            # Spiritual Concepts
            'dharma', '‡§ß‡§∞‡•ç‡§Æ', 'karma', '‡§ï‡§∞‡•ç‡§Æ', 'yoga', '‡§Ø‡•ã‡§ó', 'bhakti', '‡§≠‡§ï‡•ç‡§§‡§ø',
            'atma', '‡§Ü‡§§‡•ç‡§Æ‡§æ', 'soul', 'spiritual', '‡§Ü‡§ß‡•ç‡§Ø‡§æ‡§§‡•ç‡§Æ‡§ø‡§ï', 'meditation', '‡§ß‡•ç‡§Ø‡§æ‡§®',
            'moksha', '‡§Æ‡•ã‡§ï‡•ç‡§∑', 'liberation', 'enlightenment', 'nirvana', 'samadhi',

            # Life Guidance Topics
            'life', '‡§ú‡•Ä‡§µ‡§®', 'purpose', 'meaning', 'path', '‡§Æ‡§æ‡§∞‡•ç‡§ó', 'way',
            'problem', '‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ', 'solution', '‡§∏‡§Æ‡§æ‡§ß‡§æ‡§®', 'help', '‡§Æ‡§¶‡§¶', 'guide',
            'chahta', 'chahti', 'chahiye', 'karna', 'karu', 'karoon', 'karun',
            'batao', 'bataiye', 'btao', 'btaiye', 'samjhao',

            # Emotions & Mental States
            'anger', '‡§ï‡•ç‡§∞‡•ã‡§ß', 'peace', '‡§∂‡§æ‡§Ç‡§§‡§ø', 'fear', '‡§≠‡§Ø', 'anxiety', '‡§ö‡§ø‡§Ç‡§§‡§æ',
            'stress', 'depression', 'sad', '‡§¶‡•Å‡§ñ', 'happy', '‡§∏‡•Å‡§ñ', 'joy', '‡§Ü‡§®‡§Ç‡§¶',
            'confused', '‡§Ö‡§∏‡§Æ‡§Ç‡§ú‡§∏', 'lost', 'hopeless', '‡§®‡§ø‡§∞‡§æ‡§∂', 'pareshan',
            'dukhi', 'udaas', 'akela', 'tanha', 'dara', 'ghabra',
            'gussa', 'ghussa', 'chinta', 'tension', 'takleef', 'mushkil',
            'suicidal', 'suicide', 'marna', 'jeena', 'zindagi', 'jindagi',

            # Relationships
            'love', '‡§™‡•ç‡§∞‡•á‡§Æ', 'hate', '‡§ò‡•É‡§£‡§æ', 'family', '‡§™‡§∞‡§ø‡§µ‡§æ‡§∞', 'friend', '‡§Æ‡§ø‡§§‡•ç‡§∞',
            'relationship', '‡§∏‡§Ç‡§¨‡§Ç‡§ß', 'marriage', '‡§µ‡§ø‡§µ‡§æ‡§π', 'breakup',
            'mummy', 'mama', 'papa', 'father', 'mother', 'bhai', 'behen', 'sister',
            'brother', 'dost', 'yaar', 'girlfriend', 'boyfriend', 'wife', 'husband',
            'pati', 'patni', 'beta', 'beti', 'ghar', 'gharwale', 'parents',
            'rishtedaar', 'rishta', 'shaadi', 'divorce', 'pyaar', 'mohabbat',

            # Work, Study & Career
            'work', '‡§ï‡§æ‡§Æ', 'job', '‡§®‡•å‡§ï‡§∞‡•Ä', 'duty', '‡§ï‡§∞‡•ç‡§§‡§µ‡•ç‡§Ø', 'responsibility',
            'success', '‡§∏‡§´‡§≤‡§§‡§æ', 'failure', '‡§Ö‡§∏‡§´‡§≤‡§§‡§æ', 'exam', '‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ',
            'padhai', 'padhna', 'study', 'college', 'school', 'university',
            'naukri', 'business', 'career', 'future', 'australia', 'abroad',
            'videsh', 'bahar', 'jaana', 'jane', 'permission', 'allow',
            'mana', 'roka', 'rok', 'nahi dete', 'nahi de rahi', 'nahi de rhe',

            # Existential Questions
            'why', '‡§ï‡•ç‡§Ø‡•ã‡§Ç', 'how', '‡§ï‡•à‡§∏‡•á', 'what is', '‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à', 'who am i',
            'death', '‡§Æ‡•É‡§§‡•ç‡§Ø‡•Å', 'birth', '‡§ú‡§®‡•ç‡§Æ', 'suffering', '‡§ï‡§∑‡•ç‡§ü',
            'desire', '‡§á‡§ö‡•ç‡§õ‡§æ', 'attachment', '‡§Æ‡•ã‡§π', 'ego', '‡§Ö‡§π‡§Ç‡§ï‡§æ‡§∞',

            # Common Hinglish life situation words
            'kya karu', 'kya karun', 'kya karoon', 'kya karna chahiye',
            'kaise karu', 'kaise karun', 'kaise karoon',
            'sahi', 'galat', 'theek', 'bura', 'acha', 'achha',
            'meri', 'mera', 'mere', 'mujhe', 'mujhko', 'main', 'hum',
            'nahi', 'nhi', 'mat', 'ruk', 'rok',
        ]

        # If query contains any relevant keyword, it's likely valid
        if any(keyword in query_lower for keyword in relevant_keywords):
            logger.info(f"‚úÖ Relevant query detected: '{query}'")
            return True, ""

        # DEFAULT: Allow all queries that aren't explicitly irrelevant.
        # Real life problems come in many forms - benefit of doubt always.
        # Only hard-coded irrelevant patterns (sports, politics, etc.) are rejected above.
        logger.info(f"‚úÖ Allowing query (default pass): '{query}'")
        return True, ""

    def search_with_llm(self, query: str, conversation_history: List[Dict] = None, **kwargs) -> Dict[str, Any]:
        """End-to-end RAG answer with conversation context."""
        
        # 0. Check for Greeting
        if self._is_greeting(query):
             return {
                 "answer": "‡§∞‡§æ‡§ß‡•á ‡§∞‡§æ‡§ß‡•á! ‡§Æ‡•à‡§Ç ‡§∂‡•ç‡§∞‡•Ä ‡§ï‡•É‡§∑‡•ç‡§£ ‡§π‡•Ç‡§Å‡•§ ‡§ï‡§π‡§ø‡§Ø‡•á, ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?",
                 "shlokas": [],
                 "llm_used": True
             }

        # 0.5 Check if query is relevant (Fast Regex Check)
        is_relevant, rejection_message = self._is_relevant_to_krishna(query)
        if not is_relevant:
            logger.warning(f"Rejecting irrelevant query (Regex): '{query}'")
            return {
                "answer": rejection_message,
                "shlokas": [],
                "llm_used": False,
                "rejected": True
            }

        # 0.6 AI Understanding & Relevance Check (Smart Gatekeeper)
        understanding = self._understand_query(query)
        
        if not understanding.get('is_relevant', True):
            logger.warning(f"Rejecting irrelevant query (AI): '{query}'")
            return {
                "answer": """‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•à‡§Ç ‡§∂‡•ç‡§∞‡•Ä ‡§ï‡•É‡§∑‡•ç‡§£ ‡§π‡•Ç‡§Å ‡§î‡§∞ ‡§ï‡•á‡§µ‡§≤ ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç, ‡§Ü‡§ß‡•ç‡§Ø‡§æ‡§§‡•ç‡§Æ‡§ø‡§ï‡§§‡§æ, ‡§î‡§∞ ‡§≠‡§ó‡§µ‡§¶ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•á ‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§® ‡§¶‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å‡•§

‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç:
‚Ä¢ ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§® (‡§ï‡•ç‡§∞‡•ã‡§ß, ‡§°‡§∞, ‡§ö‡§ø‡§Ç‡§§‡§æ, etc.)
‚Ä¢ ‡§ï‡§∞‡•ç‡§Æ, ‡§ß‡§∞‡•ç‡§Æ, ‡§î‡§∞ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç
‚Ä¢ ‡§∞‡§ø‡§∂‡•ç‡§§‡•ã‡§Ç ‡§î‡§∞ ‡§≠‡§æ‡§µ‡§®‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç
‚Ä¢ ‡§ß‡•ç‡§Ø‡§æ‡§®, ‡§∂‡§æ‡§Ç‡§§‡§ø, ‡§î‡§∞ ‡§Ü‡§§‡•ç‡§Æ-‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç

‡§ï‡•É‡§™‡§Ø‡§æ ‡§á‡§® ‡§µ‡§ø‡§∑‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡•á‡§Ç‡•§ üôè""",
                "shlokas": [],
                "llm_used": False,
                "rejected": True
            }

        # 1. Retrieve - Increased to 5 to give LLM better options
        shlokas = self.search(query, top_k=5, understanding=understanding)
        
        # Log retrieved shlokas for debugging
        logger.info(f"üìñ Retrieved {len(shlokas)} shlokas for query: '{query}'")
        for i, s in enumerate(shlokas, 1):
            logger.info(f"  {i}. Gita {s['id']}: {s['meaning'][:80]}...")
        
        # 2. Generate with conversation context
        if not self.llm_generator:
             return {"answer": "LLM not connected.", "shlokas": shlokas, "llm_used": False}
        
        # Map emotional state to tone to save one LLM call
        emotional_state = understanding.get('emotional_state', 'neutral')
        tone_map = {
            'crisis': 'crisis',
            'distress': 'distress',
            'depressive': 'distress',
            'angry': 'distress',
            'fear': 'distress',
            'confused': 'distress'
        }
        tone = tone_map.get(emotional_state, 'general')
             
        return self.llm_generator.generate_answer(
            query, 
            shlokas, 
            conversation_history=conversation_history or [],
            tone=tone
        )

    # Legacy wrappers for compatibility
    def _get_llm_generator(self):
        """Backwards compatibility for CLI."""
        if not self.llm_generator:
            self.llm_generator = LLMAnswerGenerator(api_key=self.groq_api_key)
        return self.llm_generator

    def format_results(self, results: List[Dict[str, Any]], query: str, method: str) -> str:
        """Format results for display (fallback mode)."""
        output = [f"\nSearch Results for: '{query}'", "-" * 70]
        for i, res in enumerate(results, 1):
             meaning = res.get('meaning', 'No meaning available')[:200].replace('\n', ' ')
             output.append(f"{i}. Gita {res['id']}")
             output.append(f"   {meaning}...")
             output.append("")
        return "\n".join(output)
